{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS187\n",
    "## Lab 1-4 – Discriminative methods for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New bits of Python used for the first time in the _solution set_ for this lab, and which you may therefore find useful:\n",
    "\n",
    "* `numpy.exp`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation – Loading packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import math\n",
    "from math import log2\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('tableau-colorblind10')\n",
    "\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "# Otter grader which we use for grading does not support\n",
    "# !command, so we need to use shell(command) instead\n",
    "# to run shell commands\n",
    "def shell(str):\n",
    "    file = os.popen(str)\n",
    "    result = file.read()\n",
    "    print (result)\n",
    "    if file.close () is not None:\n",
    "        print ('failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Federalist data from the json file\n",
    "shell('wget -nv -N -P data https://github.com/nlp-course/data/raw/master/Federalist/federalist_data.json')\n",
    "with open('data/federalist_data.json', 'r') as fin:\n",
    "    dataset = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As before, we extract the papers by either of Madison and Hamilton to serve as training data.\n",
    "training = list(filter(lambda ex: ex['authors'] in ['Madison', 'Hamilton'],\n",
    "                       dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "You've read about logistic regression, a method for classification that is discriminative rather than generative. Like the generative Naive Bayes method, each example is characterized by a vector of features (the counts of word types for a text, say, as for the _Federalist_ example we've been using). In logistic regression, each such feature is assigned a weight, and the score for an example is given by weighting each feature value by its weight and summing the result; that is, the score is the dot product of the feature vector and the weight vector. Let's take an example, one of the Federalist papers. We'll extract from the training data the counts for the first example in the training set. That's the feature vector for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training0_counts = training[0]['counts']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose the weights for the features are as given by the following vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [-.1, .2, .3, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "What would the weighted sum of the counts with these weights be? Feel free to use `np.dot` to take the dot product for you.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: wtd_sum\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtd_sum = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"wtd_sum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question:** What is the range of possible values that such a weighted sum can take on?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_1\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "In order to have a standard way of comparing these numbers, it helps to be able to place them on a fixed scale, from 0 to 1, say. This way, they can be interpreted as probabilities. We use the _logistic function_ ($\\sigma$) to carry out this conversion:\n",
    "\n",
    "$$ \\sigma(x) = \\frac{1}{1 + e^{-k x}}$$\n",
    "\n",
    "In addition to its argument $x$, the function takes an additional parameter $k$, which we will explore shortly.\n",
    "\n",
    "Define a function `sigma` implementing the logistic function. (We've established a default value for `k` of 1 in the header line below.)\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: sigma\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(x, k=1):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"sigma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a sense of the logistic function, we graph it for several values of $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_plot():\n",
    "    x = np.linspace(-2, 2, 100)\n",
    "    fig, ax = plt.subplots()\n",
    "    for k in [0, 1, 2, 10]:\n",
    "        ax.plot(x, sigma(x, k), label = f\"k = {k}\")\n",
    "    plt.title(\"Logistic functions\")\n",
    "    plt.legend()\n",
    "    \n",
    "sigma_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question:** What does the $k$ parameter do to the logistic function?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "manual: true\n",
    "name: open_response_2\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "The logistic function, when applied to the weighted average above is quite close to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma(wtd_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In the _Federalist Papers_ classification problem, there are only two classes, so we can use this single value to determine the classification. For a feature vector $\\mathbf{x}$, we'll take the model to predict the probability of the author being Hamilton (say), as\n",
    "\n",
    "$$\\Prob(\\mathrm{Hamilton} \\given \\mathbf{x}) = \\sigma(\\mathbf{w} \\cdot \\mathbf{x})$$\n",
    "\n",
    "Therefore, \n",
    "\n",
    "$$\\Prob(\\mathrm{Madison} \\given \\mathbf{x}) = 1 - \\sigma(\\mathbf{w} \\cdot \\mathbf{x})$$\n",
    "\n",
    "since there are only two classes.\n",
    "\n",
    "> When there are more than two classes, we'd use a generalization of the sigmoid function, called [softmax](https://en.wikipedia.org/wiki/Softmax_function).\n",
    "\n",
    "Define a function `predict_lr` that calculates the probability of Hamilton being the author of an example text, given a weight vector and the feature vector for the example text.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: predict_lr\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_lr(weights, features):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a logistic regression model to predict Federalist authorship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following two training examples (examples 0 and 9) from the Federalist dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in [0, 9]:\n",
    "    pprint(training[example])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above, a logistic regression model is defined by a vector of weights $\\mathbf{w}$, like these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Calculate the predicted Hamilton probabilities for the two examples (examples 0 and 9) above.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: prob_hamilton_examples\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_hamilton_example0 = ...\n",
    "prob_hamilton_example9 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"prob_hamilton_examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"example 0 prob: {prob_hamilton_example0:.3f}\\n\"\n",
    "      f\"example 9 prob: {prob_hamilton_example9:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question:** What does this model predict about the two training examples? Is it correct?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_3\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## Training a logistic regression model\n",
    "\n",
    "Of course, this is just one of a gazillion models, since we could have set the weights in all kinds of ways. How should we come up with a _good_ model, a good setting of the weights? Ideally, we'd try to find a set of weights that predicts all of the training data well. This is the problem of _training_ a logistic regression model. Let's try another set of weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_new = [0.1, 0.2, 0.3, -5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Calculate the probabilities generated by the model for these weights.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: prob_hamilton_examples_new\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_hamilton_example0_new = ...\n",
    "prob_hamilton_example9_new = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"prob_hamilton_examples_new\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question:**  Is this a better model or a worse model, at least as far as the two sample examples go? \n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_4\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "An ideal model would give a probability of 1 to the Hamilton examples and a 0 to the Madison examples.\n",
    "For the two sample examples, you'll have noticed that the new weights generate not 1 and 0, respectively, but numbers quite a bit closer to 1 and 0.\n",
    "\n",
    "We could continue trying different weight values to try to improve the performance of the model on these training examples (and others) by trial and error, but a more systematic method is needed. We define a _loss function_, which specifies how bad a model is, and try to minimize the loss function by _stochastic gradient descent_.\n",
    "\n",
    "We'll do a few steps of the process here by hand. It's sufficiently tedious that it's far better to deploy computers on the task.\n",
    "\n",
    "## Cross-entropy loss function\n",
    "\n",
    "We'll use the cross-entropy loss function. For an example $i$, we'll use $\\mathbf{x}^{(i)}$ for the feature vector, and $y^{(i)}$ for the actual (gold) label (1 or 0). The predicted label will be as per the logistic regression model $\\sigma(\\mathbf{w} \\cdot \\mathbf{x}^{(i)})$, which we will call $\\hat{y}^{(i)}$.\n",
    "\n",
    "The cross-entropy loss for example $i$ as per a model $\\mathbf{w}$ is\n",
    "$$L_{CE}(\\mathbf{w}) = -(y^{(i)} \\log \\hat{y}^{(i)} + (1-y^{(i)}) \\log (1-\\hat{y}^{(i)}))$$\n",
    "\n",
    "We define a function to compute the cross-entropy loss for a particular model (weight vector), example (feature vector), and gold label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(weights, features, correct):\n",
    "    \"\"\"Returns the cross-entropy loss for a weight vector, a feature\n",
    "       vector and a gold label\"\"\"\n",
    "    y_hat = predict_lr(weights, features)\n",
    "    return -(correct * log2(y_hat)\n",
    "             + (1 - correct) * log2(1 - y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Use the `loss` function to determine the cross-entropy loss for example 0 for the original model that we used (`weights`), and for the new model (`weights_new`).\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: loss_example0_old_and_new\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_example0_old = ...\n",
    "loss_example0_new = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"loss_example0_old_and_new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Old model loss: {loss_example0_old:.3f}\\n\"\n",
    "      f\"New model loss: {loss_example0_new:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question:** Which of the models is better (at least on this example)?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_5\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## Gradient of the loss function\n",
    "\n",
    "We want to find the weights that minimize the loss function. We use gradient descent:\n",
    "\n",
    "1. Find the gradient of the loss function, the direction in which it is increasing fastest.\n",
    "2. Take a step in the opposite direction.\n",
    "3. Repeat.\n",
    "\n",
    "For cross-entropy loss, recall that the partial derivative of the loss function with respect to a single weight $w_j$ is\n",
    "\n",
    "$$ \\frac{\\partial L_{CE}(\\mathbf{w})}{\\partial w_j} = (\\hat{y} - y) x_j $$\n",
    "\n",
    "The gradient combines these partial derivatives for all of the weights.\n",
    "\n",
    "$$ \\nabla L_{CE}(\\mathbf{w}) = \\left[ \\begin{array}{c}\n",
    "    \\frac{\\partial L_{CE}(\\mathbf{w})}{\\partial w_1}\\\\\n",
    "    \\frac{\\partial L_{CE}(\\mathbf{w})}{\\partial w_2}\\\\\n",
    "    \\vdots \\\\\n",
    "    \\frac{\\partial L_{CE}(\\mathbf{w})}{\\partial w_m}\n",
    "    \\end{array} \\right] $$\n",
    "\n",
    "Let's work out an example, using example 0.\n",
    "\n",
    "The counts for example 0 are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "training[0]['counts']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the original weights, recall, were"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "What is the gradient vector for these weights and training example?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: grad_vector\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "grad_vector = ...\n",
    "grad_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"grad_vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2 is to adjust the weights in the _opposite_ direction of the gradient.\n",
    "In this case, we compute the new weight vector $w'$ by adding to the weight vector a fraction of the negative gradient:\n",
    "\n",
    "$$ \\mathbf{w}' = \\mathbf{w} - \\eta \\nabla L_{CE}(\\mathbf{w}) $$\n",
    "\n",
    "Here, $\\eta$ is the _learning rate_. The larger $\\eta$ is, the more we move in each step, but if $\\eta$ is too large we risk overshooting. We'll use a learning rate of 0.1 for now. (Setting good learning rates is one aspect of the black arts of machine learning.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Calculate the new weight vector.\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: weights_updated\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_updated = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"weights_updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(weights_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do these weights perform on the training example we've been using? Let's see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_example0_updated = loss(weights_updated, training[0]['counts'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Old model loss: {loss_example0_old:.3f}\\n\"\n",
    "      f\"New model loss: {loss_example0_new:.3f}\\n\"\n",
    "      f\"Updated model loss: {loss_example0_updated:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "If you did this all right, the loss for the updated model, which was generated by taking a single step opposite the gradient from the old model is not only better than the old model, but better than the new model we used above as well. \n",
    "\n",
    "What about the loss on the other example we've been using (example 9)? Calculate the loss for example 9 with the old model, the new model, and the updated model:\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: weights_updated_9\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_example9_old = loss(weights, training[9]['counts'], 0) # Solution\n",
    "loss_example9_new = loss(weights_new, training[9]['counts'], 0) # Solution\n",
    "loss_example9_updated = loss(weights_updated, training[9]['counts'], 0) # Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"weights_updated_9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Old model loss: {loss_example9_old:.3f}\\n\"\n",
    "      f\"New model loss: {loss_example9_new:.3f}\\n\"\n",
    "      f\"Updated model loss: {loss_example9_updated:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question:** Did the update to the model improve its performance on example 9 or make it worse?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: open_response_6\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "Step 3 is to repeat the process for this and other training examples. We could recalculate the gradient and take another step to improve further, and take steps to improve the other training examples, and so on and so forth, eventually converging on a model that works well over the entire training set. But doing so manually in this way is too tedious. We need to be able to do these kinds of computations at scale. Fortunately, we'll soon be turning to packages that allow specifying these larger-scale computations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of lab 1-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
